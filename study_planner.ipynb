{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Navaneeth-18bit/Study-Planner-AI-chatbot/blob/main/study_planner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vIMnAT-OETf",
        "outputId": "002c9df7-ecca-4de8-a948-95b6f4876434"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.40.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.8.93)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7XBBDaLOKh8",
        "outputId": "939546a0-1cf7-40ba-9740-a1e4cb2e1849"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agentic AI (type 'exit' to quit)\n",
            "You: I have two subjects DBMS and OS\n",
            "Agent: You are a study planner assistant Study Plan: =DBMS: 2.0 hours = OS: 2.0 hours Now Explain this plan clearly. Give step-by-step guidance. Add time managment tips. You are a study planner assistant Study Plan: =DBMS: 2.0 hours = OS: 2.0 hours Now Explain this plan clearly. Give step-by-step guidance. Add time managment tips. You are a study planner assistant Study Plan: =DBMS: 2.0 hours = OS: 2.0 hours Now Explain this plan clearly. Give step-by-step guidance. Add time managment\n",
            "You: exit\n",
            "Agent: Goodbye!\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "import re\n",
        "\n",
        "llm = pipeline(\n",
        "    \"text2text-generation\",\n",
        "    model=\"google/flan-t5-large\",\n",
        "    max_length=128\n",
        ")\n",
        "\n",
        "print(\"Agentic AI (type 'exit' to quit)\")\n",
        "\n",
        "def extract_subjects(text):\n",
        "  prompt = f\"\"\"\n",
        "  Extract the study subjects mentioned in the following text.\n",
        "  Return ONLY a comma-seperated list.\n",
        "  No explanation.\n",
        "\n",
        "  Text:\n",
        "  {user_input}\n",
        "  \"\"\"\n",
        "\n",
        "  result = llm(prompt)[0][\"generated_text\"]\n",
        "  subjects = [s.strip() for s in result.split(\",\") if s.strip()]\n",
        "  return subjects\n",
        "\n",
        "\n",
        "def allocate_study_time(subjects, total_hours=4):\n",
        "  \"\"\"simple logic: split hours evenly among subjects\n",
        "  \"\"\"\n",
        "\n",
        "  n = len(subjects)\n",
        "  per_subject = round(total_hours/n,1)\n",
        "  plan = {subject: per_subject for subject in subjects}\n",
        "  return plan\n",
        "\n",
        "def format_plan(plan):\n",
        "  lines=[]\n",
        "  for subject, hours in plan.items():\n",
        "    lines.append(f\"={subject}: {hours} hours\")\n",
        "  return \"\\n\".join(lines)\n",
        "\n",
        "def chat_tool(user_input):\n",
        "\n",
        "  subjects = extract_subjects(user_input)\n",
        "\n",
        "  if not subjects:\n",
        "    return \"I couldn't detect sunjects. Please mention them clearly\"\n",
        "\n",
        "  plan = allocate_study_time(subjects)\n",
        "  formatted_plan = format_plan(plan)\n",
        "\n",
        "\n",
        "\n",
        "  prompt_chat = f\"\"\"\n",
        "  You are a study planner assistant\n",
        "\n",
        "\n",
        "  Study Plan:\n",
        "  {formatted_plan}\n",
        "\n",
        "  Now Explain this plan clearly.\n",
        "  Give step-by-step guidance.\n",
        "  Add time managment tips.\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  return llm(prompt_chat)[0][\"generated_text\"].strip()\n",
        "\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == \"exit\":\n",
        "        print(\"Agent: Goodbye!\")\n",
        "        break\n",
        "\n",
        "    result = chat_tool(user_input)\n",
        "    print(\"Agent:\", result)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import re\n",
        "import datetime\n",
        "\n",
        "llm = pipeline(\n",
        "    \"text2text-generation\",\n",
        "    model=\"google/flan-t5-large\",\n",
        "    max_length=128\n",
        ")\n",
        "\n",
        "print(\"Agentic AI (type 'exit' to quit)\")\n",
        "\n",
        "\n",
        "TIME_KEYWORDS = [\"hour\",\"hours\",\"time\",\"schedule\",\"plan\",\"split\",\"manage\",\"study time\"]\n",
        "\n",
        "MATH_KEYWORDS = [\"+\",\"-\",\"*\",\"/\"]\n",
        "\n",
        "STUDY_INTENT = [\"study\",\"plan\",\"schedule\",\"timetable\",\"prepare\"]\n",
        "\n",
        "MEMORY = {\n",
        "    \"time_minutes\": None,\n",
        "    \"subjects\": None,\n",
        "    \"chapters\":None\n",
        "}\n",
        "\n",
        "\n",
        "SUBJECT_KEYWORDS = [\n",
        "    # Core subjects\n",
        "    \"dbms\", \"os\", \"cn\", \"ai\", \"ml\",\n",
        "    \"maths\", \"physics\", \"chemistry\",\n",
        "    \"english\", \"history\", \"biology\",\n",
        "\n",
        "    # Study intent words\n",
        "    \"study\", \"studying\", \"learn\", \"learning\",\n",
        "    \"revise\", \"revision\", \"prepare\", \"preparation\",\n",
        "    \"plan\", \"schedule\", \"timetable\",\n",
        "    \"subject\", \"syllabus\", \"exam\"\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def calculator_tool(text):\n",
        "    \"\"\"Calculate simple math expressions.\"\"\"\n",
        "    try:\n",
        "        # Extract numbers and operators\n",
        "        expression = re.findall(r\"[0-9]+|[\\+\\-\\*/]\", text)\n",
        "        return str(eval(\"\".join(expression)))\n",
        "    except:\n",
        "        return \"I couldn't calculate that.\"\n",
        "\n",
        "def time_managment_tool(text):\n",
        "    global MEMORY\n",
        "\n",
        "    # -------- TIME --------\n",
        "    hours = re.findall(r\"\\d+\", text)\n",
        "    if hours:\n",
        "        MEMORY[\"time_minutes\"] = int(hours[0]) * 60\n",
        "\n",
        "    if MEMORY[\"time_minutes\"] is None:\n",
        "        return \"How much total time do you have?\"\n",
        "\n",
        "    total_minutes = MEMORY[\"time_minutes\"]\n",
        "\n",
        "    # -------- SUBJECTS --------\n",
        "    subjects = re.findall(r\"(DBMS|OS|CN|AI|ML)\", text, re.IGNORECASE)\n",
        "    if subjects:\n",
        "        MEMORY[\"subjects\"] = subjects\n",
        "\n",
        "    if MEMORY[\"subjects\"] is None:\n",
        "        return \"Which subjects should I plan for?\"\n",
        "\n",
        "    subjects = MEMORY[\"subjects\"]\n",
        "    subject_count = len(subjects)\n",
        "\n",
        "    # -------- CHAPTERS --------\n",
        "    chapter_match = re.search(r\"(\\d+)\\s*chapters?\", text)\n",
        "    if chapter_match:\n",
        "        MEMORY[\"chapters\"] = int(chapter_match.group(1))\n",
        "    elif MEMORY[\"chapters\"] is None:\n",
        "        MEMORY[\"chapters\"] = 1   # default\n",
        "\n",
        "    chapters = MEMORY[\"chapters\"]\n",
        "\n",
        "    # -------- STUDY TIME --------\n",
        "    study_time = total_minutes // subject_count\n",
        "\n",
        "    if study_time < 30:\n",
        "        break_time = 0\n",
        "    elif study_time <= 60:\n",
        "        break_time = 5\n",
        "    else:\n",
        "        break_time = 10\n",
        "\n",
        "    chapter_time = study_time // chapters\n",
        "\n",
        "    # -------- RESPONSE --------\n",
        "    response = []\n",
        "    response.append(\"ðŸ“˜ STUDY PLAN\\n\")\n",
        "    response.append(f\"You have {subject_count} subject(s) to cover\")\n",
        "    response.append(f\"Total chapters: {chapters}\\n\")\n",
        "\n",
        "    for subject in subjects:\n",
        "        response.append(\n",
        "            f\"ðŸ“š {subject.upper()}\\n\"\n",
        "            f\"â€¢ Total study time: {study_time} minutes\\n\"\n",
        "            f\"â€¢ Study each chapter for {chapter_time} minutes\\n\"\n",
        "            f\"â€¢ Take a {break_time}-minute break after each chapter or after 1 or 1.5 hours\\n\"\n",
        "        )\n",
        "\n",
        "    response.append(\n",
        "        \"ðŸ’¡ Tips:\\n\"\n",
        "        \"â€¢ Focus on understanding, not memorizing\\n\"\n",
        "        \"â€¢ Revise after every chapter\\n\"\n",
        "        \"â€¢ Small progress every day builds confidence\\n\"\n",
        "        \"â€¢ You are doing great â€” keep going ðŸ’ª\"\n",
        "    )\n",
        "\n",
        "    return \"\\n\".join(response)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def clarification_response(text):\n",
        "\n",
        "  \"\"\"This is the agent asks clarification for the study plan response\"\"\"\n",
        "\n",
        "  global MEMORY\n",
        "\n",
        "  if MEMORY[\"time_minutes\"] is None:\n",
        "    return \"How much total time do you have\"\n",
        "\n",
        "  if MEMORY[\"subjects\"] is None:\n",
        "    return \"Which subjects should i plan for?\"\n",
        "\n",
        "  return \"Please give more details.\"\n",
        "\n",
        "  needs_time = not re.search(r\"\\d+\", text)\n",
        "  needs_subject = not any(word in text for word in SUBJECT_KEYWORDS)\n",
        "  if needs_time and needs_subject:\n",
        "      return \"How much total time do you have and which subjects should I plan for?\"\n",
        "  elif needs_time:\n",
        "      return \"How much total time do you have?\"\n",
        "  elif needs_subject:\n",
        "      return \"Which subjects should I plan for?\"\n",
        "  else:\n",
        "      return \"Can you give more details?\"\n",
        "\n",
        "    #-------CHAT TOOL--------\n",
        "\n",
        "def chat_tool():\n",
        "  prompt_chat = f\"\"\"\n",
        "Define the following term or answer the question clearly.\n",
        "\n",
        "Rules:\n",
        "- Give a correct definition or explanation\n",
        "- Use simple English\n",
        "- Do NOT repeat the question\n",
        "- Do NOT output instructions\n",
        "\n",
        "Input: {user_input}\n",
        "Output:\n",
        "\"\"\"\n",
        "  return llm(prompt_chat)[0][\"generated_text\"].strip()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def decide_and_act(user_input):\n",
        "\n",
        "    has_math = any(op in user_input for op in MATH_KEYWORDS)\n",
        "    has_number = bool(re.search(r\"\\d+\", user_input))\n",
        "    has_time_word = any(word in user_input for word in TIME_KEYWORDS)\n",
        "    has_subject = any(word in user_input for word in SUBJECT_KEYWORDS)\n",
        "    has_study_intent = any(word in user_input for word in STUDY_INTENT)\n",
        "\n",
        "    # ---- MULTI TOOL ----\n",
        "    if has_math and has_study_intent:\n",
        "        calc = calculator_tool(user_input)\n",
        "        return time_managment_tool(user_input + \" \" + calc)\n",
        "\n",
        "    # ---- MATH ----\n",
        "    if has_math:\n",
        "        return calculator_tool(user_input)\n",
        "\n",
        "    # ---- STUDY PLANNING ----\n",
        "    if has_study_intent:\n",
        "        if has_number and has_time_word and has_subject:\n",
        "            return time_managment_tool(user_input)\n",
        "        else:\n",
        "            return clarification_response(user_input)\n",
        "\n",
        "    # ---- NORMAL CHAT ----\n",
        "    return chat_tool()\n",
        "def normalize_input(text):\n",
        "  \"\"\"Normalize the input of the prompt\"\"\"\n",
        "  text = text.lower()\n",
        "  text = text.replace(\"hrs\",\"hours\")\n",
        "  text = text.replace(\"hr\",\"hour\")\n",
        "  text = text.replace(\"mins\",\"minutes\")\n",
        "  text = text.replace(\"min\",\"miunte\")\n",
        "  return text\n",
        "\n",
        "\n",
        "\n",
        "while True:\n",
        "\n",
        "  raw_input = input(\"You:\")\n",
        "\n",
        "  if raw_input.lower() == \"exit\":\n",
        "    print(\"Agent: Goodbye!\")\n",
        "    break\n",
        "\n",
        "\n",
        "\n",
        "  user_input = normalize_input(raw_input)\n",
        "\n",
        "  result = decide_and_act(user_input)\n",
        "  print(\"Agent:\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PN5gqjf1ARG",
        "outputId": "fb71df1e-8c74-4494-ff31-8881f3eaf718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agentic AI (type 'exit' to quit)\n",
            "You:say helloo\n",
            "Agent: Say helloo\n",
            "You:make a study plan for DBMS 7 hrs\n",
            "Agent: ðŸ“˜ STUDY PLAN\n",
            "\n",
            "You have 1 subject(s) to cover\n",
            "Total chapters: 1\n",
            "\n",
            "ðŸ“š DBMS\n",
            "â€¢ Total study time: 420 minutes\n",
            "â€¢ Study each chapter for 420 minutes\n",
            "â€¢ Take a 10-minute break after each chapter or after 1 or 1.5 hours\n",
            "\n",
            "ðŸ’¡ Tips:\n",
            "â€¢ Focus on understanding, not memorizing\n",
            "â€¢ Revise after every chapter\n",
            "â€¢ Small progress every day builds confidence\n",
            "â€¢ You are doing great â€” keep going ðŸ’ª\n",
            "You:who is Mahathma Ghandhi?\n",
            "Agent: Mahatma Ghandhi (, also Romanized as Mhathm Gdh; also known as Mhathm Gdh; also known as Mhathm Gdh; also known as Mhathm Gdh; also known as Mhathm Gdh; also known as Mhathm Gdh; also known as Mhathm Gdh; also known as Mhathm G\n",
            "You:What is Normalization?\n",
            "Agent: Normalization is the process of determining the normal distribution of a variable.\n",
            "You:who is APJ Abdul Kalam?\n",
            "Agent: APJ Abdul Kalam is a Pakistani politician.\n",
            "You:Who is APJ Abdul Kalam?\n",
            "Agent: APJ Abdul Kalam is a Pakistani politician.\n",
            "You:What is ktu?\n",
            "Agent: KTU may refer to:\n",
            "You:What is carrom baord?\n",
            "Agent: Carrom baord is a variant of the game carrom.\n",
            "You:Rules of carrom board>\n",
            "Agent: Rules of carrom board\n",
            "You:Rules of carrom board\n",
            "Agent: Rules of carrom board\n",
            "You:what are the rules of carrom board\n",
            "Agent: The rules of carrom board are the same as those of any other board game.\n",
            "You:Tell me the rules\n",
            "Agent: Use simple English\n",
            "You:Can you tell me the rules of carrom boarf?\n",
            "Agent: Do NOT repeat the question\n",
            "You:exit\n",
            "Agent: Goodbye!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/Qk+99GEUldCUXGDEWl6e",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}